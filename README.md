# Wikipedia Analysis with Pyspark

## Intoduction
The aim of this project was to analyze the content of Wikepia and to train a model to classify articles in 15 categories. Considering the great amount of data, this project was implemented on Databricks using Pyspark to parallelise computation.

## Project workflow
- EDA of Wikipedia dataset
- Training of two models (Naive-Bayes), one using the entire article and one using only the summary
- Evualuation and comparison of the models 
